<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 17px; /* 19 */
    font-weight: 600 /* 1000 */
  }
  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }
  </style>
  <link rel="shortcut icon" href="images/fd_logo.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Jiahao Zhan</title>
  <meta name="Jiahao Zhan's Homepage" http-equiv="Content-Type" content="Jiahao Zhan's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('send', 'pageview');
    </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>
 
<body>
<table width="900" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Jiahao Zhan 「詹佳豪」</pageheading><br>
  </p>

  <tr>
    <td width="30%" valign="top"><a href="images/jiahaozhan.jpg"><img src="images/jiahaozhan.jpg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    | <a href="data/Jiahao_Zhan_s_CV.pdf">CV</a> |
    <a href="mailto:22307140116@m.fudan.edu.cn">Email</a> |
    <a href="https://scholar.google.com/citations?user=ICZu1WMAAAAJ&hl=en">Google Scholar</a> |
    <br/>
    | <a href="https://github.com/JohnZhan2023">Github</a> | 
    </p>
    <!-- <p align="center" style="margin-top:-8px;"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="twitter-follow-button twitter-follow-button-rendered" style="position: static; visibility: visible; width: 156px; height: 20px;" title="Twitter Follow Button" src="https://platform.twitter.com/widgets/follow_button.2f70fb173b9000da126c79afe2098f02.en.html#dnt=false&amp;id=twitter-widget-0&amp;lang=en&amp;screen_name=TairanHe99&amp;show_count=false&amp;show_screen_name=true&amp;size=m&amp;time=1706734206165" data-screen-name=""></iframe><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p> -->
    </td>
    <td width="70%" valign="top" align="justify">
      <p>I am a junior at <a href="https://www.fudan.edu.cn/">Fudan University</a>, majoring in Artificial Intelligence. I am currently a research intern in <a href="https://svl.stanford.edu">Stanford Vision and Learning (SVL) Lab</a> advised by <a href="https://jiajunwu.com">Jiajun Wu</a>. Before that, I conducted research with <a href="https://cqf.io">Qifeng Chen</a> at <a href="https://cqf.io">Visual Intelligence Lab</a> of <a href="https://www.ust.hk/">Hong Kong University of Science and Technology</a>. I also worked as a research intern at <a href="https://sqz.ac.cn/">Shanghai Qi Zhi Institute</a> advised by <a href="https://hangzhaomit.github.io/">Hang Zhao</a> and with <a href="https://hangzhaomit.github.io/">Dequan Wang</a> at <a href="https://www.shlab.org.cn/">Shanghai AI Lab</a>.
      </p>

      <!-- <p>Goal: challenge conventional notions of what robots can achieve, develop robots that improves everyone's life. Focus: developing intelligent robots being able to do useful tasks with <u>intelligence, generalizability, agility and safety</u>. Method: learning-based methods that scale with the computation and data. Robots: Mobile robots, legged robots, robotic manipulators, and humanoid robots.
      </p> -->

      <p><strong>Focus:</strong> 
      My research lies at the intersection of computer graphics and computer vision. I am particularly interested in <u>AIGC</u> and <u>3D vision</u>. I aim to leverage state-of-the-art video and image generative models to create <u>4D representations</u>, building effective <u>generative simulators</u> as world models.
      </p>

      <p>Email: 22307140116 [AT] m.fudan.edu.cn & jiahao14 [AT] stanford.edu
      </p>
    </td>
  </tr>
</table>

<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <tr>
    <td width="40%" valign="top" align="center">
    <img src="images/gan_rm/demo.png" alt="sym" width="90%" style="padding-top:0px; padding-bottom:0px; border-radius:15px;">
    </td>
    <td width="60%" valign="top">
      <p>
      <heading>Fake it till You Make it: Reward Modeling as Discriminative Prediction</heading><br>
      Runtao Liu, Jiahao Zhan, Yingqing He, Chen Wei, Alan Yuille, Qifeng Chen<br>
      2025<br><strong style="color: red;">(Submitted to NeurIPS 2025)</strong>
      </p>
      <div class="paper" id="gan_rm">
      <a href="javascript:toggleblock('gan_rm_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('gan_rm')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/">arXiv</a>

      <p align="justify"> <i id="gan_rm_abs">An effective reward model plays a pivotal role in reinforcement learning for post-training enhancement of visual generative models. However, current approaches of reward modeling suffer from implementation complexity due to their reliance on extensive human-annotated preference data or meticulously engineered quality dimensions that are often incomplete and engineering-intensive. Inspired by adversarial training in generative adversarial networks (GANs), this paper proposes GAN-RM, an efficient reward modeling framework that eliminates manual preference annotation and explicit quality dimension engineering. Our method trains the reward model through discrimination between a small set of representative, unpaired target samples(denoted as Preference Proxy Data) and model-generated ordinary outputs, requiring only a few hundred target samples. Comprehensive experiments demonstrate our GAN-RM's effectiveness across multiple key applications including test-time scaling implemented as Best-of-N sample filtering, post-training approaches like Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).</i></p>

<pre xml:space="preserve">
@article{liu2025fake,
  title={Fake it till You Make it: Reward Modeling as Discriminative Prediction},
  author={Liu, Runtao and Zhan, Jiahao and He, Yingqing and Wei, Chen and Yuille, Alan and Chen, Qifeng},
  journal={arXiv preprint},
  year={2025},
  note={Submitted to NeurIPS 2025}
}
</pre>
      </div>
    </td>
  </tr>

</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://github.com/Tsinghua-MARS-Lab/StateTransformer">
    <img src="images/str2/demo.gif" alt="sym" width="90%" style="padding-top:0px; padding-bottom:0px; border-radius:15px;">

    </a></td>
    <td width="60%" valign="top">
      <p><a href="https://github.com/Tsinghua-MARS-Lab/StateTransformer" id="HOVER">
      <heading>Generalizing Motion Planners with Mixture of Experts for Autonomous Driving</heading></a><br>
      Qiao Sun*, Huimin Wang*, Jiahao Zhan, Fan Nie, Xin Wen, Leimeng Xu, Kun Zhan, Peng Jia, Xianpeng Lang, Hang Zhao <br>
      2024<br><strong style="color: red;">(Accepted by ICRA 2025)</strong>
      </p>
      <div class="paper" id="hover">
      <a href="https://tsinghua-mars-lab.github.io/StateTransformer/">webpage</a> |
      <a href="https://tsinghua-mars-lab.github.io/StateTransformer/All_materials/Scaling_for_Generalizations_with_Mixture_of_Experts_on_Plannings.pdf">pdf</a> |
      <a href="javascript:toggleblock('hover_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('hover')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/2410.15774">arXiv</a> 

      

      <p align="justify"> <i id="hover_abs">Large real-world driving datasets have sparked significant research into various aspects of data-driven motion planners for autonomous driving. These include data augmentation, model architecture, reward design, training strategies, and planner pipelines. These planners promise better generalizations on complicated and few-shot cases than previous methods. However, experiment results show that many of these approaches produce limited generalization abilities in planning performance due to overly complex designs or training paradigms. In this paper, we review and benchmark previous methods focusing on generalizations. The experimental results indicate that as models are appropriately scaled, many design elements become redundant. We introduce StateTransformer-2 (STR2), a scalable, decoder-only motion planner that uses a Vision Transformer (ViT) encoder and a mixture-of-experts (MoE) causal Transformer architecture. The MoE backbone addresses modality collapse and reward balancing by expert routing during training. Extensive experiments on the NuPlan dataset show that our method generalizes better than previous approaches across different test sets and closed-loop simulations. Furthermore, we assess its scalability on billions of real-world urban driving scenarios, demonstrating consistent accuracy improvements as both data and model size grow.</i></p>

<pre xml:space="preserve">
  @misc{sun2024generalizingmotionplannersmixture,
    title={Generalizing Motion Planners with Mixture of Experts for Autonomous Driving}, 
    author={Qiao Sun and Huimin Wang and Jiahao Zhan and Fan Nie and Xin Wen and Leimeng Xu and Kun Zhan and Peng Jia and Xianpeng Lang and Hang Zhao},
    year={2024},
    eprint={2410.15774},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    url={https://arxiv.org/abs/2410.15774}, 
}
</pre>
      </div>
    </td>
  </tr>

</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://github.com/">
    <img src="images/MAC/demo.png" alt="sym" width="90%" style="padding-top:0px; padding-bottom:0px; border-radius:15px;">

    </a></td>
    <td width="60%" valign="top">
      <p>
      <heading>MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding</heading><br>
      Mohan Jiang, Jin Gao, Jiahao Zhan, Dequan Wang <br>
      2025<br><strong style="color: red;">(Submitted to COLM 2025)</strong>
      </p>
      <div class="paper" id="mac">

        <a href="javascript:toggleblock('mac_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('mac_abs')" class="togglebib">bibtex</a> |
        <a href="https://arxiv.org/">arXiv</a> 
  
        
  
        <p align="justify"> <i id="mac_abs">As multimodal large language models (MLLMs) grow increasingly capable, fixed benchmarks are gradually losing their effectiveness in evaluating high-level scientific understanding. In this paper, we introduce the Multimodal Academic Cover benchmark (MAC), a live benchmark that could continuously evolve with scientific advancement and model progress. MAC leverages over 25,000 image-text pairs sourced from issues of top-tier scientific journals such as Nature, Science, and Cell, challenging MLLMs to reason across abstract visual and textual scientific content. Experiments on our most recent yearly snapshot, MAC-2025, reveal that while MLLMs demonstrate strong perceptual abilities, their cross-modal scientific reasoning remains limited. To bridge this gap, we propose DAD, a lightweight inference-time approach that enhances MLLMs by extending MLLM visual features with language space reasoning, achieving performance improvements of up to 11%. Finally, we highlight the live nature of MAC through experiments on updating journal covers and models for curation, illustrating its potential to remain aligned with the frontier of human knowledge.

        </i></p>
  
  <pre xml:space="preserve">
    to be released
  </pre>
        </div>
      </td>
    </tr>

</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Projects</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <tr>
    <td width="40%" valign="top" align="center">
          <img src="images/PointCom/award.png" alt="sym" width="70%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
    </td>
    <td width="60%" valign="top">
      <p>
      <heading>Shape Completion and Reconstruction of Sweet Peppers Challeng (ECCV workshop)</heading><br>
      </p>

      <p align="justify"> <i id="wkfg_abs">The Third Prize</i></p>

      </div>
    </td>
  </tr>
</table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

  <tr>
    <td width="40%" valign="top" align="center">
          <img src="images/OptiPrompt/image.png" alt="sym" width="70%" style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto;">
    </td>
    <td width="60%" valign="top">
      <p><a href="https://github.com/Infinite-FDU/OptiPrompt" id="AUTOCOST">
      <heading>Intel LLM-based Application Innovation Contest (Team Leader)</heading></a><br>
      </p>
      <div class="paper" id="autocost">
      <a href="https://www.bilibili.com/video/BV1494y1L7pT/?spm_id_from=333.999.0.0"> Press conference</a> 
      

      <p align="justify"> <i id="wkfg_abs">The Second Prize</i></p>

      </div>
    </td>
  </tr>
</table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody>
      <tr>
          <td style="padding:0px">
              <br>
              <br>
              <div>
                <div id="clustrmaps-widget" style="width: 150px; height: 150px; overflow: hidden; display: flex; align-items: center; justify-content: center;">
                  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=xPJuZpcL_UB5B7o0hHDHIZmlLsO3cXw-kjzxUUE0Ji4"></script>
              </div>
              
                  <!-- <a target="_top" href="http://clustrmaps.com/site/1acpn?utm_source=widget&amp;utm_campaign=widget_ctr" id="clustrmaps-widget-v2" class="clustrmaps-map-control" style="width: 300px;">
-->                               </div>
          </td>
      </tr>
  </tbody>
</table>








<hr/>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
    <tr><td><br><p align="right">
    Website template from <a href="http://www.cs.berkeley.edu/~barron/">here</a> and <a href="http://www.cs.cmu.edu/~dpathak/">here</a>
    </font></p></td></tr>
</table>

  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('gan_rm_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('mac_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('material_review_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('ieee_iot_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('acm_turc_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('aog_mcts_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('pragmatics_marl_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('collab_marl_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('rma_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('energyloco_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('navloco_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('wococo_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('omnih2o_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('hover_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('h2o_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('agile-but-safe_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('safedpa_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('acs_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('saferl_survey_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('patchail_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('sisos_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('uaissa_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('autocost_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('a2ls_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('issa_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('ebil_abs');
</script>
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('maniploco_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('parkour_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('mobile_aloha_abs');
</script>
</body>

</html>
